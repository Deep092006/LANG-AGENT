import { ChatPromptTemplate, MessagesPlaceholder } from "@langchain/core/prompts";
import { ChatPromptValue } from "@langchain/core/prompt_values";
import { Chatmodel } from "../utils/Llm.js"; // ðŸš€ Pre-configured LLM instance (Google/ChatGPT, etc.)
import { AIMessage, HumanMessage } from "langchain";
import { configDotenv } from "dotenv";
configDotenv();

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// ðŸ§  System Prompt Templates
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// ðŸŽ¯ Prompt for initial tweet generation
const generateTweetPrompt = ChatPromptTemplate.fromMessages([
  {
    role: "system",
    content:
      "You are a Twitter tech influencer assistant tasked with writing excellent tweets. " +
      "Generate the most engaging, high-quality tweet possible for the user's request. " +
      "If the user gives suggestions or feedback, respond with a refined version of your previous attempts. " +
      "Return only the tweet text â€” no explanations or extra output.",
  },
  new MessagesPlaceholder("messages"),
]);

// ðŸ§© Prompt for tweet refinement (feedback + improvement)
const refineTweetPrompt = ChatPromptTemplate.fromMessages([
  {
    role: "system",
    content:
      "You are a viral Twitter influencer reviewing a tweet. " +
      "Provide clear, actionable feedback â€” no single-word or vague comments. " +
      "Focus on improving virality, tone, clarity, and engagement style. " +
      "Keep it concise, constructive, and avoid unnecessary text.",
  },
  new MessagesPlaceholder("messages"),
]);

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// âš™ï¸ Core Logic: Generation + Refinement
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// ðŸª¶ Step 1: Generate a tweet from user input
export const generateTweet = async (messages) => {
  const input = { messages };
  const promptValue = await generateTweetPrompt.formatPromptValue(input);
  const response = await Chatmodel.invoke(promptValue);
  return new AIMessage(response.content); // ðŸ§  LLM output as AI message
};

// ðŸ” Step 2: Refine or review the tweet with actionable feedback
export const refineTweet = async (messages) => {
  const input = { messages };
  const promptValue = await refineTweetPrompt.formatPromptValue(input);
  const response = await Chatmodel.invoke(promptValue);
  return new HumanMessage(response.content); // ðŸ’¬ Feedback returned as Human message
};
